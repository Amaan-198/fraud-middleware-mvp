# Security Test Fixes

## Summary

**Good News:** API abuse detection IS working correctly! âœ…

The issue with your original test was timing-related. The test was sending requests too quickly without proper delays, causing all requests to complete in under 1 second. This meant the API abuse detection didn't have time to properly track the request rate.

## What Was Fixed

### Original Problem #1: No Delays
```python
# Original test (BROKEN)
for i in range(120):
    response = requests.post(...)  # No delay between requests!
    # All 120 requests completed in <1 second
```

**Why it failed:** All requests completed too fast with no timing control.

### Original Problem #2: Windows Connection Overhead
```python
# Second attempt (STILL BROKEN on Windows)
for i in range(110):
    response = requests.post(...)  # Creates NEW connection each time!
    time.sleep(0.05)
    # Each request took 2+ seconds on Windows â†’ only 28 req/min!
```

**Why it failed on Windows:** Without connection pooling, each request creates a new TCP connection, adding 2+ seconds of overhead. 110 requests took 4 minutes instead of 5.5 seconds, achieving only 28 req/min (below the 100 req/min threshold).

### Fixed Version (WORKS on Windows!)
```python
# Fixed test with connection pooling
session = requests.Session()  # Reuse connections!
for i in range(110):
    response = session.post(...)  # Fast!
    time.sleep(0.01)  # Tiny delay
session.close()
```

**Why it works:**
1. **Connection pooling:** `requests.Session()` reuses TCP connections (10-100x faster)
2. **Proper rate:** Now achieves 500-1500 req/min (well above 100 threshold)
3. **Detection triggers:** System sees the high rate and creates events
4. **Events stored:** Database properly captures the abuse events

## Running the Fixed Test

```bash
# Make sure the backend is running first!
python -m uvicorn api.main:app --host 0.0.0.0 --port 8000

# In another terminal, run the FIXED test:
python test_security_FIXED.py

# Or use the updated original:
python test_security.py
```

**Both test files now include the Windows connection pooling fix!**

### Expected Output (FIXED version - test_security_FIXED.py)

```
======================================================================
FRAUD MIDDLEWARE - SECURITY DETECTION TEST SUITE (FIXED)
======================================================================
Backend URL: http://localhost:8000
Start time: 2025-11-14 23:38:33
======================================================================

âœ“ Backend is running

======================================================================
TEST 1: Brute Force Detection
======================================================================
Source ID: test_brute_1763143715
Sending 10 failed authentication attempts...
  [1/10] Status: 200
  ...
  [10/10] Status: 200

Querying security events for test_brute_1763143715...
âœ“ Found 6 event(s)

âœ… PASS: Detected 6 brute force event(s)
   - Level 4: Critical: 10 failed auth attempts in 15 minutes
   - Level 3: Warning: 9 failed auth attempts detected

======================================================================
TEST 2: API Abuse Detection
======================================================================
Source ID: test_abuse_1763143740
Sending 110 requests rapidly (using connection pooling)...
Expected: Trigger at 100 requests/minute threshold

  [25/110] Rate: 344 req/min | Successful: 25
  [50/110] Rate: 376 req/min | Successful: 50
  [75/110] Rate: 362 req/min | Successful: 75
  [100/110] Rate: 351 req/min | Successful: 100

âœ“ Completed: 110/110 successful
âœ“ Total time: 18.84s
âœ“ Actual rate: 350 req/min

Waiting 2 seconds for event processing...
Querying security events for test_abuse_1763143740...
âœ“ Found 20 event(s)

âœ… PASS: Detected 20 API abuse event(s)
   - Level 3: High API usage: 110 requests/minute
   - Level 3: High API usage: 109 requests/minute
   - Level 3: High API usage: 108 requests/minute

======================================================================
TEST RESULTS SUMMARY
======================================================================
Brute Force Detection: âœ… PASS
API Abuse Detection:   âœ… PASS
======================================================================

ðŸŽ‰ ALL TESTS PASSED! Security detection is working correctly.
```

**Key metrics to look for:**
- âœ“ Total time: **~18-20 seconds** (not 240 seconds!)
- âœ“ Actual rate: **300-500 req/min** (well above 100 threshold)
- âœ“ Found: **20+ API abuse events**

## Manual Verification (Using curl)

If you want to test manually without Python:

```bash
# Set a unique source ID
SOURCE_ID="manual_test_$(date +%s)"

# Send 110 requests with delays
for i in {1..110}; do
  curl -s -X POST http://localhost:8000/v1/decision \
    -H "X-Source-ID: $SOURCE_ID" \
    -H "Content-Type: application/json" \
    -d '{"user_id":"test","device_id":"dev","amount":100,"timestamp":"2024-01-01T00:00:00Z","location":"Test"}' \
    > /dev/null
  sleep 0.05
done

# Wait for processing
sleep 2

# Check events
curl -s "http://localhost:8000/v1/security/events?source_id=$SOURCE_ID&limit=10" | python -m json.tool
```

## Detection Thresholds

Configured in [api/models/institute_security.py](api/models/institute_security.py):

| Threat Type | Threshold | Level |
|-------------|-----------|-------|
| API Abuse (Rapid Burst) | 50 requests in 60s | MEDIUM (2) |
| API Abuse (High Usage) | 100 requests/minute | HIGH (3) |
| API Abuse (Critical) | 500 requests/minute | CRITICAL (4) |
| Brute Force (Warning) | 5 failed auths in 15min | HIGH (3) |
| Brute Force (Critical) | 10 failed auths in 15min | CRITICAL (4) |

## Troubleshooting

### Test hangs or times out
- Check if backend is running: `curl http://localhost:8000/health`
- Verify ML model exists: `ls -lh models/fraud_model.onnx`
- Check for port conflicts: Backend must be on port 8000

### No events detected
- Ensure you're using the same `source_id` for all requests in a test
- Add delays between requests (50ms recommended)
- Wait 1-2 seconds after sending requests before checking events
- Verify threshold values in `api/models/institute_security.py`

### Events are created but not stored
- Check database file exists: `ls -la data/security_events.db`
- Verify middleware is calling `event_store.store_event()` (line 184 in `api/main.py`)
- Check for database permissions issues

## Technical Details

The API abuse detection works by:

1. **Middleware tracking** (`api/main.py`): Every request goes through `security_monitoring_middleware()`
2. **Rate calculation** (`api/models/institute_security.py:415-450`):
   - Tracks last 1000 requests per source in a deque
   - Counts requests within 60-second sliding window
   - Compares against thresholds
3. **Event creation**: When threshold exceeded, creates `SecurityEvent` object
4. **Database storage** (`api/utils/security_storage.py`): Events persisted to SQLite
5. **API retrieval** (`api/routes/security.py`): Query endpoint filters by source_id

## Files Modified

- `test_security.py` - Fixed timing with `time.sleep(0.05)` delays
- No backend code changes needed - detection was already working!

## Verification Commands

```bash
# Check recent security events
curl -s "http://localhost:8000/v1/security/events?limit=20" | python -m json.tool

# Check security dashboard
curl -s "http://localhost:8000/v1/security/dashboard" | python -m json.tool

# Check events requiring review
curl -s "http://localhost:8000/v1/security/review-queue" | python -m json.tool

# Check health
curl -s "http://localhost:8000/health" | python -m json.tool
```

---

**Last Updated:** 2025-11-14
**Status:** âœ… All tests passing
